{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream # access webcam\n",
    "import argparse # command line arguments\n",
    "import imutils # image processing\n",
    "import time # insert sleep call for camera to warm up\n",
    "import cv2 # opencv bindings\n",
    "import os # files paths agnostic of OS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Object detection (face, eyes, mouth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Argument parser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"cascades\": \"cascades\",\n",
    "    \"input\": \"my-video.mp4\",\n",
    "    \"output\": \"output.avi\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading haar cascades...\n"
     ]
    }
   ],
   "source": [
    "# initialize a dictionary that maps the name of the haar cascades to\n",
    "# their filenames\n",
    "# key is name of detector\n",
    "# value is the filename corresponding to detector\n",
    "detectorPaths = {\n",
    "\t\"face\": \"haarcascade_frontalface_default.xml\",\n",
    "\t\"eyes\": \"haarcascade_eye.xml\",\n",
    "\t\"smile\": \"haarcascade_smile.xml\",\n",
    "}\n",
    "\n",
    "# initialize a dictionary to store our haar cascade detectors\n",
    "# load each cascade individually\n",
    "print(\"[INFO] loading haar cascades...\")\n",
    "detectors = {}\n",
    "\n",
    "# populate the dictionary above\n",
    "# loop over our detector paths\n",
    "# store on our disk\n",
    "for (name, path) in detectorPaths.items():\n",
    "\t# load the haar cascade from disk and store it in the detectors\n",
    "\t# dictionary\n",
    "\tpath = os.path.sep.join([args[\"cascades\"], path])\n",
    "\t# key is name = value is the path from disk\n",
    "\t# this loads the pre-trained classifier from disk\n",
    "\tdetectors[name] = cv2.CascadeClassifier(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] opening video file...\n"
     ]
    }
   ],
   "source": [
    "# grab a reference to the video file and initialize pointer to output\n",
    "# video file\n",
    "print(\"[INFO] opening video file...\")\n",
    "vs = cv2.VideoCapture(args[\"input\"]) # initialize video capture\n",
    "writer = None\n",
    "\n",
    "# image processing in this loop\n",
    "# loop over the frames from the video stream\n",
    "# read the next frame\n",
    "# resize it\n",
    "# convert to grayscale\n",
    "# apply face detector\n",
    "# then, eye detector\n",
    "# then, mouth detector\n",
    "while True:\n",
    "\t# grab the next frame\n",
    "\tframe = vs.read()[1]\n",
    "\n",
    "\t# if we did not grab a frame then we have reached the end of the\n",
    "\t# video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\n",
    "\t# rotate the image 90 degrees if wanted for image processing\n",
    "\t#frame = imutils.rotate(frame, -90)\n",
    "\n",
    "    # resize the frame and convert it to grayscale\n",
    "\tframe = imutils.resize(frame, width=500)\n",
    "\t# common to apply on graycsale images\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# perform face detection using the appropriate haar cascade\n",
    "\tfaceRects = detectors[\"face\"].detectMultiScale(\n",
    "\t\t# this parameters should be controlled and tuned\n",
    "\t\tgray, scaleFactor=1.05, minNeighbors=5, minSize=(30, 30),\n",
    "\t\tflags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "\t# output from above is set of bounding boxes\n",
    "\t# loop over the face bounding boxes\n",
    "\tfor (fX, fY, fW, fH) in faceRects:\n",
    "\t\t# extract the face ROI (region of interest)\n",
    "\t\t# using basic image cropping\n",
    "\t\tfaceROI = gray[fY:fY+ fH, fX:fX + fW]\n",
    "\n",
    "\t\t# apply eyes detection to the face ROI\n",
    "\t\teyeRects = detectors[\"eyes\"].detectMultiScale(\n",
    "\t\t\tfaceROI, scaleFactor=1.1, minNeighbors=10,\n",
    "\t\t\tminSize=(15, 15), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "\t\t# apply smile detection to the face ROI\n",
    "\t\tsmileRects = detectors[\"smile\"].detectMultiScale(\n",
    "\t\t\tfaceROI, scaleFactor=1.1, minNeighbors=10,\n",
    "\t\t\tminSize=(15, 15), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "\t\t# we add back in the face (f) coordinates to apply the\n",
    "\t\t# detections to the original image and original detection location\n",
    "\t\t# loop over the eye (e) bounding boxes\n",
    "\t\tfor (eX, eY, eW, eH) in eyeRects:\n",
    "\t\t\t# draw the eye bounding box\n",
    "\t\t\tptA = (fX + eX, fY + eY)\n",
    "\t\t\tptB = (fX + eX + eW, fY + eY + eH)\n",
    "\t\t\tcv2.rectangle(frame, ptA, ptB, (0, 0, 255), 2)\n",
    "\n",
    "\t\t# loop over the smile (s) bounding boxes\n",
    "\t\tfor (sX, sY, sW, sH) in smileRects:\n",
    "\t\t\t# draw the smile bounding box\n",
    "\t\t\tptA = (fX + sX, fY + sY)\n",
    "\t\t\tptB = (fX + sX + sW, fY + sY + sH)\n",
    "\t\t\tcv2.rectangle(frame, ptA, ptB, (255, 0, 0), 2)\n",
    "\n",
    "\t\t# draw the face bounding box on the frame\n",
    "\t\tcv2.rectangle(frame, (fX, fY), (fX + fW, fY + fH),\n",
    "\t\t\t(0, 255, 0), 2)\n",
    "\n",
    "\t# if the video writer is None *AND* we are supposed to write\n",
    "\t# the output video to disk initialize the writer\n",
    "\tif writer is None and args[\"output\"] is not None:\n",
    "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "\t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 20,\n",
    "\t\t\t(frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "\t# if the writer is not None, write the frame to disk\n",
    "\tif writer is not None:\n",
    "\t\twriter.write(frame)\n",
    "\n",
    "# do a bit of cleanup\n",
    "vs.release()\n",
    "\n",
    "# check to see if the video writer point needs to be released\n",
    "if writer is not None:\n",
    "\twriter.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3.1 Copyright (c) 2000-2020 the FFmpeg developers\r\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.27)\r\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.3.1_4 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-libsoxr --enable-videotoolbox --disable-libjack --disable-indev=jack\r\n",
      "  libavutil      56. 51.100 / 56. 51.100\r\n",
      "  libavcodec     58. 91.100 / 58. 91.100\r\n",
      "  libavformat    58. 45.100 / 58. 45.100\r\n",
      "  libavdevice    58. 10.100 / 58. 10.100\r\n",
      "  libavfilter     7. 85.100 /  7. 85.100\r\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\r\n",
      "  libswscale      5.  7.100 /  5.  7.100\r\n",
      "  libswresample   3.  7.100 /  3.  7.100\r\n",
      "  libpostproc    55.  7.100 / 55.  7.100\r\n",
      "Input #0, avi, from 'output.avi':\r\n",
      "  Metadata:\r\n",
      "    encoder         : Lavf58.76.100\r\n",
      "  Duration: 00:00:13.75, start: 0.000000, bitrate: 4255 kb/s\r\n",
      "    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 500x280, 4263 kb/s, 20 fps, 20 tbr, 20 tbn, 20 tbc\r\n",
      "Stream mapping:\r\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\r\n",
      "Press [q] to stop, [?] for help\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mprofile High, level 2.1, 4:2:0, 8-bit\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0m264 - core 161 r3027 4121277 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=20 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\r\n",
      "Output #0, mp4, to 'output.mp4':\r\n",
      "  Metadata:\r\n",
      "    encoder         : Lavf58.45.100\r\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 500x280, q=-1--1, 20 fps, 10240 tbn, 20 tbc\r\n",
      "    Metadata:\r\n",
      "      encoder         : Lavc58.91.100 libx264\r\n",
      "    Side data:\r\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\r\n",
      "frame=  275 fps=0.0 q=-1.0 Lsize=     599kB time=00:00:13.60 bitrate= 360.8kbits/s speed=25.3x    \r\n",
      "video:595kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.678942%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mframe I:2     Avg QP:21.02  size: 22040\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mframe P:69    Avg QP:22.64  size:  5811\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mframe B:204   Avg QP:26.43  size:   801\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mconsecutive B-frames:  1.1%  0.0%  0.0% 98.9%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mmb I  I16..4:  2.5% 85.9% 11.5%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mmb P  I16..4:  0.9%  8.2%  0.9%  P16..4: 35.6% 19.3% 17.8%  0.0%  0.0%    skip:17.4%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mmb B  I16..4:  0.1%  0.6%  0.1%  B16..8: 28.3%  5.1%  1.3%  direct: 1.2%  skip:63.3%  L0:46.2% L1:44.2% BI: 9.6%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0m8x8 transform intra:82.1% inter:76.8%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mcoded y,uvDC,uvAC intra: 77.6% 64.2% 23.7% inter: 12.8% 16.5% 5.2%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mi16 v,h,dc,p: 16% 17%  7% 60%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 21% 33%  3%  2%  3%  3%  4%  4%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 36% 30%  9%  3%  4%  5%  4%  5%  5%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mi8c dc,h,v,p: 42% 30% 23%  4%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mWeighted P-Frames: Y:0.0% UV:0.0%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mref P L0: 41.3% 10.4% 36.5% 11.8%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mref B L0: 69.4% 23.3%  7.2%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mref B L1: 92.0%  8.0%\r\n",
      "\u001B[1;36m[libx264 @ 0x7ff7ca818200] \u001B[0mkb/s:354.03\r\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i output.avi output.mp4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}